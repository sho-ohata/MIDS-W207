{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn import preprocessing as pre\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Clean-up some of the features\n",
    "all_train = pd.read_csv('data/train.csv')\n",
    "all_train = all_train.reindex(np.random.permutation(all_train.index))\n",
    "all_train['Breed'] = all_train['Breed'].str.replace('Black/Tan', 'BlackTan')\n",
    "all_train['Breed'] = all_train['Breed'].str.replace('/Unknown', ' Unknown')\n",
    "all_train['Breed'] = all_train['Breed'].str.replace('St. Bernard Rough Coat', 'StBernard')\n",
    "all_train['Breed'] = all_train['Breed'].str.replace('St. Bernard Smooth Coat', 'StBernard')\n",
    "all_train['Breed'] = all_train['Breed'].str.replace('German Shorthair Pointer', 'Pointer')\n",
    "all_train['Breed'] = all_train['Breed'].str.replace('German Wirehaired Pointer', 'Pointer')\n",
    "all_train['Breed'] = all_train['Breed'].str.replace('Dachshund Longhair', 'Dachshund')\n",
    "all_train['Breed'] = all_train['Breed'].str.replace('Dachshund Wirehair', 'Dachshund')\n",
    "all_train['Breed'] = all_train['Breed'].str.replace('English Pointer', 'Pointer')\n",
    "all_train['Breed'] = all_train['Breed'].str.replace('Chihuahua Shorthair', 'Chihuahua')\n",
    "all_train['Breed'] = all_train['Breed'].str.replace('Chihuahua Longhair', 'Chihuahua')\n",
    "all_train['Breed'] = all_train['Breed'].str.replace('Alaskan Husky', 'Husky')\n",
    "all_train['Breed'] = all_train['Breed'].str.replace('Siberian Husky', 'Husky')\n",
    "\n",
    "all_train['Breed'] = all_train['Breed'].str.replace(' ', '')\n",
    "all_train['Breed'] = all_train['Breed'].str.replace('PitBull', ' PitBull ')\n",
    "all_train['Breed'] = all_train['Breed'].str.replace('Rottweiler', ' Rottweiler ')\n",
    "all_train['Breed'] = all_train['Breed'].str.replace('/', ' known ')\n",
    "all_train['Breed'] = all_train['Breed'].str.replace('Mix', ' Mix ')\n",
    "#all_train['Breed'] = all_train['Breed'].str.replace('Mix', '')\n",
    "all_train['Breed'] = all_train['Breed'].str.replace('Unknown', '')\n",
    "all_train['Breed'] = all_train['Breed'].str.replace('Australian', '')\n",
    "all_train['Breed'] = all_train['Breed'].str.replace('American', '')\n",
    "all_train['Breed'] = all_train['Breed'].str.replace('German', '')\n",
    "all_train['Breed'] = all_train['Breed'].str.replace('YorkshireTerrier', ' Yorkshire ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Breed feature has many different combinations this function breaks it down to extract the most significant features\n",
    "##and renames non-significant ones to \"other\"\n",
    "\n",
    "def best_feat_breed(all_train):\n",
    "    best_0 = pd.DataFrame()\n",
    "    best_1 = pd.DataFrame()\n",
    "    best_2 = pd.DataFrame()\n",
    "    best_3 = pd.DataFrame()\n",
    "    best_4 = pd.DataFrame()\n",
    "\n",
    "    for trial in range(100):\n",
    "        ##Randomize 100 times \n",
    "        all_train = all_train.reindex(np.random.permutation(all_train.index))\n",
    "\n",
    "        split = all_train.shape[0] // 20\n",
    "        dev = all_train[:split]\n",
    "        train = all_train[split:]\n",
    "        \n",
    "        ##Use count vectorizer\n",
    "        cv = CountVectorizer()\n",
    "        train_corpus = cv.fit_transform(train.Breed)\n",
    "        dev_corpus = cv.transform(dev.Breed)\n",
    "        features = np.array(cv.get_feature_names())\n",
    "        \n",
    "        ##Apply logistic regression to measure determine best features\n",
    "        clf = LogisticRegression(penalty='l1', C=0.5)\n",
    "        clf.fit(train_corpus, train.OutcomeType)\n",
    "        preds = clf.predict_proba(dev_corpus)\n",
    "        \n",
    "        ##Store the best features across all outcome types\n",
    "        for a in range(5):\n",
    "            if a == 0:\n",
    "                best_0 = best_0.append(pd.DataFrame(features[[np.argsort(clf.coef_[a])[-20:]]]))\n",
    "            elif a == 1:\n",
    "                best_1 = best_1.append(pd.DataFrame(features[[np.argsort(clf.coef_[a])[-20:]]]))\n",
    "            elif a == 2:\n",
    "                best_2 = best_2.append(pd.DataFrame(features[[np.argsort(clf.coef_[a])[-20:]]]))\n",
    "            elif a == 3:\n",
    "                best_3 = best_3.append(pd.DataFrame(features[[np.argsort(clf.coef_[a])[-20:]]]))\n",
    "            elif a == 4:\n",
    "                best_4 = best_4.append(pd.DataFrame(features[[np.argsort(clf.coef_[a])[-20:]]]))\n",
    "\n",
    "    best_0.columns = ['feature']\n",
    "    best_1.columns = ['feature']\n",
    "    best_2.columns = ['feature']\n",
    "    best_3.columns = ['feature']\n",
    "    best_4.columns = ['feature']\n",
    "    \n",
    "    ##Combine and get unique set of best features from the 100 trials which appeared at least 80% of the time\n",
    "    best = list(best_0.groupby('feature').size()[best_0.groupby('feature').size() > 80].index)\n",
    "    best.extend(list(best_1.groupby('feature').size()[best_1.groupby('feature').size() > 80].index))\n",
    "    best.extend(list(best_2.groupby('feature').size()[best_2.groupby('feature').size() > 80].index))\n",
    "    best.extend(list(best_3.groupby('feature').size()[best_3.groupby('feature').size() > 80].index))\n",
    "    best.extend(list(best_4.groupby('feature').size()[best_4.groupby('feature').size() > 80].index))\n",
    "    best = list(set(best))\n",
    "    \n",
    "    ##Replace non-significant words with the word other\n",
    "    cv = CountVectorizer()\n",
    "    all_train_corpus = cv.fit_transform(all_train.Breed)\n",
    "    all_corpus = np.array(cv.get_feature_names())\n",
    "    \n",
    "    other = list(set(all_corpus) - set(best))\n",
    "\n",
    "    all_train['Breed'] = [x.lower() for x in all_train['Breed']]\n",
    "\n",
    "    for x in other:\n",
    "        all_train['Breed'] = all_train['Breed'].str.replace(x, ' other ')\n",
    "        \n",
    "    return(all_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Reduce DateTime feature to month and day of week\n",
    "\n",
    "def calendar_date(all_train):\n",
    "\n",
    "    dayOfWeek={0:'Monday', 1:'Tuesday', 2:'Wednesday', 3:'Thursday', 4:'Friday', 5:'Saturday', 6:'Sunday'}\n",
    "    dayOfWeek_alt={0:'Monday', 1:'Tues-Fri', 2:'Tues-Fri', 3:'Tues-Fri', 4:'Tues-Fri', 5:'Sat-Sun', 6:'Sat-Sun'}\n",
    "    MonthName={1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'Jun', 7:'Jul', 8:'Aug', 9:'Sep',10:'Oct',11:'Nov',12:'Dec'} \n",
    "    MonthName_alt={1:'Jan-Feb', 2:'Jan-Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'Jun', 7:'Jul',\n",
    "                   8:'Aug', 9:'Sep-Nov',10:'Sep-Nov',11:'Sep-Nov',12:'Dec'}\n",
    "\n",
    "    all_train['DateTime'] = pd.to_datetime(all_train['DateTime'])\n",
    "    all_train['weekday'] = all_train['DateTime'].dt.dayofweek.map(dayOfWeek_alt)\n",
    "    all_train['month'] = all_train['DateTime'].dt.month.map(MonthName_alt)\n",
    "    \n",
    "    return (all_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Combine features and return combined numpy array which will be used as inputs into sklearn models\n",
    "\n",
    "def combine_array(dev, train):\n",
    "    ##Convert calendar date features to dummy variables\n",
    "    day_of_week_dev = np.array(pd.get_dummies(dev[['weekday','month']]))\n",
    "    day_of_week_train = np.array(pd.get_dummies(train[['weekday','month']]))\n",
    "\n",
    "    ##Determine common vocab set from dev and test\n",
    "    vectorizer = CountVectorizer(min_df=1)\n",
    "    all_vocab = vectorizer.fit_transform(pd.concat([train.Breed, dev.Breed]))\n",
    "    all_vocab = vectorizer.get_feature_names()\n",
    "    dev_vocab = vectorizer.fit_transform(dev.Breed)\n",
    "    dev_vocab = vectorizer.get_feature_names()\n",
    "    common = set(all_vocab).intersection(dev_vocab)\n",
    "    \n",
    "    ##Convert dev and train corpus to dense from sparse matrix\n",
    "    cv = CountVectorizer(vocabulary=common)\n",
    "    train_corpus = cv.fit_transform(train.Breed).todense()\n",
    "    dev_corpus = cv.transform(dev.Breed).todense()\n",
    "    \n",
    "    ##Finally combine\n",
    "    dev_combine = np.concatenate((dev_corpus, day_of_week_dev),axis=1)\n",
    "    train_combine = np.concatenate((train_corpus, day_of_week_train),axis=1)\n",
    "    \n",
    "    return dev_combine, train_combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Separate to cats and dogs\n",
    "all_train_cat = all_train[(all_train['AnimalType']=='Cat')]\n",
    "all_train_dog = all_train[(all_train['AnimalType']=='Dog')]\n",
    "\n",
    "all_train_cat = best_feat_breed(all_train_cat)\n",
    "all_train_cat = calendar_date(all_train_cat)\n",
    "all_train_dog = best_feat_breed(all_train_dog)\n",
    "all_train_dog = calendar_date(all_train_dog)\n",
    "\n",
    "split_cat = all_train_cat.shape[0] // 20\n",
    "split_dog = all_train_dog.shape[0] // 20\n",
    "\n",
    "dev_cat = all_train_cat[:split_cat]\n",
    "train_cat = all_train_cat[split_cat:]\n",
    "\n",
    "dev_dog = all_train_cat[:split_dog]\n",
    "train_dog = all_train_cat[split_dog:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dev_dog_combine, train_dog_combine = combine_array(dev_dog, train_dog)\n",
    "dev_cat_combine, train_cat_combine = combine_array(dev_cat, train_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistc Regression Log Loss: 0.996\n",
      "Logistc Regression Accuracy: 0.555 \n",
      "\n",
      "Logistc Regression Log Loss: 0.990\n",
      "Logistc Regression Accuracy: 0.572 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def Logreg(train_combine, dev_combine, train, dev):\n",
    "    clf = LogisticRegression(penalty='l1', C=0.1)\n",
    "    clf.fit(train_combine, train.OutcomeType)\n",
    "    preds = clf.predict_proba(dev_combine)\n",
    "    print 'Logistc Regression Log Loss: {:.3f}'.format(log_loss(dev.OutcomeType, preds))\n",
    "    print 'Logistc Regression Accuracy: {:.3f}'.format(clf.score(dev_combine, dev.OutcomeType)), '\\n'\n",
    "\n",
    "Logreg(train_dog_combine, dev_dog_combine, train_dog, dev_dog)\n",
    "Logreg(train_cat_combine, dev_cat_combine, train_cat, dev_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (a random forest): 0.553273427471\n",
      "Accuracy (a random forest): 0.561151079137\n"
     ]
    }
   ],
   "source": [
    "def rf(train_combine, dev_combine, train, dev):\n",
    "    rfc = RandomForestClassifier(n_estimators=100)\n",
    "    rfc.fit(train_combine, train.OutcomeType)\n",
    "\n",
    "    print 'Accuracy (a random forest):', rfc.score(dev_combine, dev.OutcomeType)\n",
    "\n",
    "rf(train_dog_combine, dev_dog_combine, train_dog, dev_dog)\n",
    "rf(train_cat_combine, dev_cat_combine, train_cat, dev_cat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
